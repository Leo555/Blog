---
title: 机器学习常用算法——支持向量机
date: 2017-01-08 21:27:24
categories: Machine Learning
tags:
- Python
- Algorithm
- Machine Learning
- scikit-learn
- SVM
---
# 支持向量机

<img src="http://img.blog.csdn.net/20130919093501390" alt="支持向量机">

支持向量机(support vector machine)是一种分类算法，通过寻求结构化风险最小来提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，即支持向量机的学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。
<!-- more -->

SVM 是一种分类方法。在这个算法中，我们将每个数据在 N 维空间中用点标出（N是你所有的特征总数），每个特征的值是一个坐标的值。
举个例子，如果我们只有身高和体重两个特征，我们会在二维空间中标出这两个变量，每个点有两个坐标（这些坐标叫做支持向量）。

现在，我们会找到将两组不同数据分开的一条直线。两个分组中距离最近的两个点到这条线的距离同时最优化。



## 原理



## SVM的优点

1. SVM学习问题可以表示为凸优化问题，因此可以利用已知的有效算法发现目标函数的全局最小值。而其他分类方法（如基于规则的分类器和人工神经网络）都采用一种基于贪心学习的策略来搜索假设空间，这种方法一般只能获得局部最优解。

2. 假设现在你是一个农场主，圈养了一批羊群，但为预防狼群袭击羊群，你需要搭建一个篱笆来把羊群围起来。但是篱笆应该建在哪里呢？你很可能需要依据牛群和狼群的位置建立一个“分类器”，比较下图这几种不同的分类器，我们可以看到SVM完成了一个很完美的解决方案。


<img src="http://img.blog.csdn.net/20131121105410546">
这个例子从侧面简单说明了SVM 使用非线性分类器的优势，而逻辑模式以及决策树模式都是使用了直线方法。


[代码地址](https://github.com/Leo555/scikit-learn_demo/tree/master/02LogisticRegression)

# 参考文献
[支持向量机通俗导论（理解SVM的三层境界）](http://blog.csdn.net/macyang/article/details/38782399/)
[支持向量机（SVM）算法](http://www.cnblogs.com/end/p/3848740.html)