---
title: Apache Hadoop入门
date: 2016-9-07 21:08:23
tags: 
- Big Data
- Hadoop
categories: Big Data
---
# 学习背景

很早就想学习大数据相关的知识，无奈一直没有契机，而且没有实际项目的学习其实比较困难，所以无从下手。这次借机ITA技术学习，正巧项目组已经开始探索大数据相关知识，所以想靠自学摸索一下。

# Apache Hadoop 简介
---

Apache Hadoop 是一个由 Apache 基金会所开发的分布式系统基础架构。可以让用户在不了解分布式底层细节的情况下，开发出可靠、可扩展的分布式计算应用。
 
Apache Hadoop 它主要有以下几个优点：

1. 高可靠性。Hadoop 按位存储和处理数据的能力值得人们信赖。
2. 高扩展性。Hadoop 是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
3. 高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。
4. 高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
5. 低成本。Hadoop 是开源的，项目的软件成本因此会大大降低。

Hadoop的核心就是HDFS和MapReduce，而两者只是理论基础，不是具体可使用的高级应用，Hadoop旗下有很多经典子项目，比如HBase、Hive等，这些都是基于HDFS和MapReduce发展出来的。要想了解Hadoop，就必须知道HDFS和MapReduce是什么。

# Apache Hadoop 核心组件

Apache Hadoop 包含以下模块：

1. Hadoop Common：常见实用工具，用来支持其他 Hadoop 模块。
2. Hadoop Distributed File System（HDFS）：分布式文件系统，它提供对应用程序数据的高吞吐量访问。
3. Hadoop YARN：一个作业调度和集群资源管理框架。
4. Hadoop MapReduce：基于 YARN 的大型数

其他与 Apache Hadoop 的相关项目包括：

1. Ambari：一个基于Web 的工具，用于配置、管理和监控的 Apache Hadoop 集群，其中包括支持 Hadoop HDFS、Hadoop MapReduce、Hive、HCatalog、HBase、ZooKeeper、Oozie、Pig 和 Sqoop。Ambari 还提供了仪表盘查看集群的健康，如热图，并能够以用户友好的方式来查看的 MapReduce、Pig 和 Hive 应用，方便诊断其性能。
2. Avro：数据序列化系统。
3. Cassandra：可扩展的、无单点故障的多主数据库。
4. Chukwa：数据采集系统，用于管理大型分布式系统。
5. HBase：一个可扩展的分布式数据库，支持结构化数据的大表存储。
6. Hive：数据仓库基础设施，提供数据汇总以及特定的查询。
7. Mahout：一种可扩展的机器学习和数据挖掘库。
8. Pig：一个高层次的数据流并行计算语言和执行框架。
9. Spark：Hadoop 数据的快速和通用计算引擎。Spark 提供了简单和强大的编程模型用以支持广泛的应用，其中包括 ETL、机器学习、流处理和图形计算。(有关 Spark 的内容，会在后面章节讲述)
10. TEZ：通用的数据流编程框架，建立在 Hadoop YARN 之上。它提供了一个强大而灵活的引擎来执行任意 DAG 任务，以实现批量和交互式数据的处理。TEZ 正在被 Hive、Pig 和 Hadoop 生态系统中其他框架所采用，也可以通过其他商业软件（例如 ETL 工具），以取代的 Hadoop MapReduce 作为底层执行引擎。
11. ZooKeeper：一个高性能的分布式应用程序协调服务。

## HDFS
HDFS（Hadoop Distributed File System，Hadoop分布式文件系统），HDFS将大文件分块存储在不同的计算机上，在文件读写的时候可以从不同计算资源的多个文件块区读取多个文件。

### HDFS的关键元素

Block：将一个文件进行分块，通常是64M。
NameNode：保存整个文件系统的目录信息、文件信息及分块信息，这是由唯一一台主机专门保存，当然这台主机如果出错，NameNode就失效了。在Hadoop2.0 开始支持activity-standy模式----如果主NameNode失效，启动备用主机运行NameNode。
DataNode：分布在普通的计算机上，用于存储Block块文件。

![HDFS](http://i4.piimg.com/567571/e14b5c00a00daa85.jpg)

### HDFS原理

HDFS体系结构中有两类节点，一类是NameNode，又叫"元数据节点"；另一类是DataNode，又叫"数据节点"。这两类节点分别承担Master和Worker具体任务的执行节点。

1）元数据节点用来管理文件系统的命名空间
其将所有的文件和文件夹的元数据保存在一个文件系统树中。

这些信息也会在硬盘上保存成以下文件：命名空间镜像(namespace image)及修改日志(edit log)

其还保存了一个文件包括哪些数据块，分布在哪些数据节点上。然而这些信息并不存储在硬盘上，而是在系统启动的时候从数据节点收集而成的。

2）数据节点是文件系统中真正存储数据的地方。
客户端(client)或者元数据信息(namenode)可以向数据节点请求写入或者读出数据块。

其周期性的向元数据节点回报其存储的数据块信息。

3）从元数据节点（secondary namenode）

从元数据节点并不是元数据节点出现问题时候的备用节点，它和元数据节点负责不同的事情。

其主要功能就是周期性将元数据节点的命名空间镜像文件和修改日志合并，以防日志文件过大。这点在下面会相信叙述。

合并过后的命名空间镜像文件也在从元数据节点保存了一份，以防元数据节点失败的时候，可以恢复。

### HDFS设计特点

1. 大数据文件，非常适合上T级别的大文件或者一堆大数据文件的存储，如果文件只有几个G甚至更小就没啥意思了。
2. 文件分块存储，HDFS会将一个完整的大文件平均分块存储到不同计算器上，它的意义在于读取文件时可以同时从多个主机取不同区块的文件，多主机读取比单主机读取效率要高得多得都。
3. 流式数据访问，一次写入多次读写，这种模式跟传统文件不同，它不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末添加内容。
4. 廉价硬件，HDFS可以应用在普通PC机上，这种机制能够让给一些公司用几十台廉价的计算机就可以撑起一个大数据集群。
5. 硬件故障，HDFS认为所有计算机都可能会出问题，为了防止某个主机失效读取不到该主机的块文件，它将同一个文件块副本分配到其它某几个主机上，如果其中一台主机失效，可以迅速找另一块副本取文件。

## MapReduce

Mapreduce是一个计算框架，既然是做计算的框架，那么表现形式就是有个输入（input），mapreduce操作这个输入（input），通过本身定义好的计算模型，得到一个输出（output），这个输出就是我们所需要的结果。

我们要学习的就是这个计算模型的运行规则。在运行一个mapreduce计算任务时候，任务过程被分为两个阶段：map阶段和reduce阶段，每个阶段都是用键值对（key/value）作为输入（input）和输出（output）。而程序员要做的就是定义好这两个阶段的函数：map函数和reduce函数。

从网上找了两个图

![mapreduce](http://i2.buimg.com/567571/ebc8b48d7b9bbb22.jpg)


![mapreduce](http://i2.buimg.com/567571/1f5b3c3d963edb93.jpg)

### Mapreduce运行机制

Mapreduce运行机制按照时间顺序包括：输入分片（input split）、map阶段、combiner阶段、shuffle阶段和reduce阶段。

1. 输入分片（input split）：在进行map计算之前，mapreduce会根据输入文件计算输入分片（input split），每个输入分片（input split）针对一个map任务，输入分片（input split）存储的并非数据本身，而是一个分片长度和一个记录数据的位置的数组，输入分片（input split）往往和hdfs的block（块）关系很密切，假如我们设定hdfs的块的大小是64mb，如果我们输入有三个文件，大小分别是3mb、65mb和127mb，那么mapreduce会把3mb文件分为一个输入分片（input split），65mb则是两个输入分片（input split）而127mb也是两个输入分片（input split），换句话说我们如果在map计算前做输入分片调整，例如合并小文件，那么就会有5个map任务将执行，而且每个map执行的数据大小不均，这个也是mapreduce优化计算的一个关键点。

2. map阶段：就是程序员编写好的map函数了，因此map函数效率相对好控制，而且一般map操作都是本地化操作也就是在数据存储节点上进行；

3. combiner阶段：combiner阶段是程序员可以选择的。Combiner是一个本地化的reduce操作，它是map运算的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作，例如单词频率做统计，map计算时候如果碰到一个hadoop的单词就会记录为1，但是这篇文章里hadoop可能会出现n多次，那么map输出文件冗余就会很多，因此在reduce计算前对相同的key做一个合并操作，那么文件会变小，这样就提高了宽带的传输效率，毕竟hadoop计算力宽带资源往往是计算的瓶颈也是最为宝贵的资源，但是combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入，例如：如果计算只是求总数，最大值，最小值可以使用combiner，但是做平均值计算使用combiner的话，最终的reduce计算结果就会出错。

4. shuffle阶段：将map的输出作为reduce的输入的过程就是shuffle了，这个是mapreduce优化的重点地方。Shuffle一开始就是map阶段做输出操作，一般mapreduce计算的都是海量数据，map输出时候不可能把所有文件都放到内存操作，因此map写入磁盘的过程十分的复杂，更何况map输出时候要对结果进行排序，内存开销是很大的，map在做输出时候会在内存里开启一个环形内存缓冲区，这个缓冲区专门用来输出的，默认大小是100mb，并且在配置文件里为这个缓冲区设定了一个阀值，默认是0.80（这个大小和阀值都是可以在配置文件里进行配置的），同时map还会为输出操作启动一个守护线程，如果缓冲区的内存达到了阀值的80%时候，这个守护线程就会把内容写到磁盘上，这个过程叫spill，另外的20%内存可以继续写入要写进磁盘的数据，写入磁盘和写入内存操作是互不干扰的，如果缓存区被撑满了，那么map就会阻塞写入内存的操作，让写入磁盘操作完成后再继续执行写入内存操作，前面我讲到写入磁盘前会有个排序操作，这个是在写入磁盘操作时候进行，不是在写入内存时候进行的，如果我们定义了combiner函数，那么排序前还会执行combiner操作。

5. reduce阶段：和map函数一样也是程序员编写的，最终结果是存储在hdfs上的。


# 结语

这篇文章仅仅是一些入门的概念，接下来会有安装和一些小Demo。
