---
title: 机器学习常用算法——决策树
date: 2017-01-07 21:27:24
categories: Algorithm
tags:
- Python
- Algorithm
- Machine Learning
- scikit-learn
- DecisionTreeClassifier
- DecisionTreeRegressor
---
# 决策树
<img src="/assets/img/决策树.png" alt="决策树">

决策树是一个非参数的监督式学习方法，主要用于分类和回归，算法的目标是通过推断数据特征，学习决策规则从而创建一个预测目标变量的模型。决策树（decision tree）是一个树结构（可以是二叉树或非二叉树）。其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。使用决策树进行决策的过程就是从根节点开始，测试待分类项中相应的特征属性，并按照其值选择输出分支，直到到达叶子节点，将叶子节点存放的类别作为决策结果。
<!-- more -->
决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。决策数有两大优点：
（1）决策树模型可以读性好，具有描述性，有助于人工分析；
（2）效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。

决策树既可以做分类，也可以做回归。

## 分类

以文章开始的图片为例子，假设银行贷款前需要审查用户信息，来确定是否批准贷款，构造数据 data.scv 如下:

> house, married, income, give_loan
1, 1, 80, 1
1, 0, 30, 1
1, 1, 30, 1
0, 1, 30, 1
0, 1, 40, 1
0, 0, 80, 1
0, 0, 78, 0
0, 0, 70, 1
0, 0, 88, 1
0, 0, 45, 0
0, 1, 87, 1
0, 0, 89, 1
0, 0, 100, 1

```python
from numpy import genfromtxt
from sklearn import tree
# 加载数据
dataset = genfromtxt('data.csv', delimiter=",")
x = dataset[1:, 0:3]
y = dataset[1:, 3]
clf = tree.DecisionTreeClassifier()
clf = clf.fit(x, y)
# 预测
print(clf.predict([[0, 0, 50]])) # [ 0.] 说明此用户不满足贷款条件
```





# 参考文献
[算法杂货铺——分类算法之决策树(Decision tree)](http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html)
[《机器学习实战》基于信息论的三种决策树算法(ID3,C4.5,CART)](http://blog.csdn.net/gamer_gyt/article/details/51242815)

