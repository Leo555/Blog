---
title: 微博情绪分析
date: 2016-10-16 22:55:00
tags: 
- Big Data
- Node
- Python
- 情绪分析
categories: Big Data 

---

# 简介
本来是ITA的一个大数据学习的项目，如今发展成这样一个情绪分析的项目，以下是我的大体思路。
1. 使用node.js爬虫每天从「新浪微博」上爬取一定数量的微博。主要实现登录，抓取发布微博，抓取关注人和粉丝的功能，暂时把数据存放在MongoDB中。
2. 对微博进行分词，分词是非常复杂的功能，需要机器学习训练模型，因此采用哈工大开源项目[「LTP-Cloud」](http://www.ltp-cloud.com/)直接调用现成API。感谢哈工大社会计算与信息检索研究中心 (HIT-SCIR)。
3. 然后对分词后的词语进行情绪分析，这里使用大连理工大学林鸿飞教授带领全体教研室成员整理而成的[「情感词汇本体库」](http://ir.dlut.edu.cn/EmotionOntologyDownload)，是目前最权威的中文情绪词典。
4. 最后使用spark将情绪分析结果进行数据整合。
<!-- more -->
## weibo_crawler
第一部分是准备数据，我的想法是随机爬取10w左右的微博用户，然后每天爬取他们前一天发布的微博作为本项目的数据源。

爬取用户信息采用递归的方式，随机以某个用户为起点，然后爬取该用户的关注和粉丝，然后递归地爬取关注和粉丝的信息。只需要得到用户名、用户ID即可。

由于新浪微博对爬虫有限制，因此爬取用户微博的时候采用定时器的方式。

由于只有登录了才能获取某个用户的个人信息和关注粉丝信息，而微博爬虫的难点就在于用户登录。

## 